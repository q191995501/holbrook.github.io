---
title: 《量化投资：数据挖掘技术与实践(MatLab版)》读书笔记第3章：数据的准备
date: 2017-09-23
category: 量化交易
tags: [数据分析, 读书笔记,]
---

 数据的准备包括收集、质量分析和预处理。

<!-- more -->


[《量化投资：数据挖掘技术与实践(MatLab版)》读书笔记目录]({% post_link quantitative_investment_index %})

# 量化投资的数据类别

量化投资相关的数据主要包括：

- 交易数据类

  + 股票交易
  + 大宗交易
  + 市场指数
  + 基金市场
  + 期货数据
  + 权证数据
  + 高频交易数据

- 上市公司类

  + 财务报表
  + 财务报告及审计
  + 财务指标分析
  + 分析师预测研究
  + 增发配股
  + 分红
  + 股东结构
  + 并购重组

- 经济与行业类

  + 宏观经济数据
  + 区域经济数据
  + 行业统计数据
  + 进出口统计数据
  + 全球经济数据
  + 外汇市场
  + 黄金市场
  + 市场波动研究

# 数据的选择

前面列出了很多数据源，具体选择哪些数据源，要根据分析目的和分析方法选取。比如：

- 基本面选股(目的)

  方法有统计模型方法(比如 主成分分析、逐步回归、分层回归等方法)和结构模型方法（比如 成长型，价值型，GARP 等）

  需要基本面数据，包括：盈利能力、成长性、盈利质量、资产运行效率、股本扩张能力、偿债能力、现金情况等

- 多因素选股（目的）

  方法如宏观经济周期、行业景气周期等。

  需要外部环境数据，如 宏观经济形势、行业发展状况等。

- 动量反转选股(目的)

  方法有很多，数据主要是市场交易数据，如动量、波动性、活跃性等。


# 数据来源和数据要素

公共的量化分析数据源主要有雅虎/新浪、大智慧、万德等。

数据对应着实体，包含多个属性。
具体的数据对象称为样本，实例。

属性通过一个数据字段表示对象的一个特征。根据不同的场景，分别称为 属性(Attribute),
特征(Feature), 维(Dimension), 变量(Variable)。

属性值可以是离散值或者连续值。

# 数据抽样

为例节省时间，在检查数据质量时一般不会检查所有数据(如果对于海量数据，在训练时也有可能不使用全部数据)。
这就需要对数据进行抽样。

抽样之前，要先对数据的分布进行探索，充分了解数据后再选择合适的抽样方法。

抽样要保证具有代表性和随机性。常用的抽样方法有：

- 简单随机抽样(Simple Random Sampling)

  用类似抽签的方式抽取样本。简单，但是不适合总体较大的情况。

- 系统抽样(Systematic Sampling)

  即机械抽样、等距抽样。如果总体分布不均匀时容易产生抽样偏差。

- 群体抽样(Cluster Sampling)

  先分群，再随机抽取几个群组。抽样误差可能比较大。

- 分层抽样(Stratified Sampling)

  如果样本的某种特征具有层次分类，可以从每层抽取一定样本。

# 数据质量分析

原始的数据可能存在错误、缺失或不一致等问题。不能盲目相信。在使用之前要先检查数据的质量。

数据质量分析的目的是评估数据的正确型和有效性。
正确性分析考察数据的缺失值、数据错误、度量标准错误、编码不一致等问题；
有效性分析主要是统计方面的信息，如占比、方差、均值、分位数等，通过这些信息了解数据的信息量程度。

数据质量分析的方法主要有：

- 值分析：对值的情况进行统计。比如：

  + 总记录数，表征数据规模
  + 唯一值数，表征数据多样性
  + 空值占比，表征无效数据的影响程度
  + 零值占比
  + 正数占比
  + 负数占比

- 统计分析：分析数据的统计学特征，包括：

  + 基本统计量：均值，最小值，最大值，标准差，极差  + 拓展统计量

    * 众数(Mode): 变量中发生频率最大的值。众数不受极端数据的影响。
    * 分位数(Median): 数据排序后，小于某个值的数据占总数的百分比。
    * 中位数：即50%分位数。代表数据总体的中等情况，可以避免极端数据的影响。
    * 偏度: 值的分布与正太分布的偏差程度。拍大怒小于/大于零称为负/正偏离。

- 频次与直方图分析

  频次图和直方图，以直观的方式展现数据的分布特征：集中趋势和离散趋势。

  直方图(hist)适合处理连续数据，找出其统计规律，从而推断总体分布特征。

  频次图适合处理离散数据，其各个取值的分布情况。可以对多个维度进行组合分析。

# 数据预处理

数据质量的三个要素：准确性、完整性、一致性

此外，可信性(Believability)和可解释性(Interpretability)也是两个重要的因素。

数据预处理主要包括四个内容：

- 数据清洗：填充缺失值，去除噪声

  缺失值处理的方法主要有删除发、插补法(均值插补，回归插补，极大似然估计)

  噪声过滤的方法主要有：回归法、均值平滑法、离群点分析法，小波去噪法。

- 数据集成: 将不同来源的数据关联起来。

- 数据归约：简化数据。可以进行属性选择和样本选择。

- 数据变换

  标准化：如 0-1标准化， Z-score 标准化（标准差标准化，处理为标准正态分布）

  离散化：将连续的属性值划分为若干段(bin)

  语义转换：如，将字符型变为离散的数值。


[《量化投资：数据挖掘技术与实践(MatLab版)》读书笔记目录]({filename}quantitative_investment_index.md)
