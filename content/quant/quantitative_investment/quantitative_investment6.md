Title: 《量化投资：数据挖掘技术与实践(MatLab版)》读书笔记第6章：数据回归方法
Date: 2017-10-08
Category: 量化交易
Tags: 数据分析, 读书笔记
Summary: 回归方法，就是处理变量之间相关关系的一种数学方法


[《量化投资：数据挖掘技术与实践(MatLab版)》读书笔记目录]({filename}quantitative_investment_index.md)

变量之间的关系可以分为两类：

- 确定性关系(函数关系): 可以通过其他变量确定一个变量
- 相关关系： 难以用精确的方法表达。比如年龄和血压的关系

回归方法，就是处理变量之间相关关系的一种数学方法。其解决问题的步骤如下：

1. 收集一组包含因变量和自变量的数据
2. 选定因变量和自变量之间的模型，利用数据按照一定方法计算出模型的参数（公式系数）
3. 利用统计分析方法对不同的模型进行比较，找出效果最好的模型
4. 判断得到的模型是否适合这组数据
5. 利用模型对因变量作出预测或解释

回归是数据挖掘最基本的方法，一般都先尝试用回归方法进行研究。

在量化投资领域，回归方法可用于研究经济走势、大盘走势、个股走势。比如，最常用的多因子模型，
就是用多元回归方法得到的。

# 回归的分类

根据回归方法中因变量的格式和回归函数的形式，可以将回归方法分为：

- 一元线性回归
- 一元非线性回归
- 多元线性回归
- 多元非线性回归

此外，还有两种特殊的回归方式：

- 逐步回归: 在回归过程中可以调整变量数
- Logistic回归， 以指数结构函数作为回归模型

# 回归效果的评价

建立回归模型，一般先绘制散点图，根据图形的样式选择回归模型，然后计算参数。
最后，对回归效果进行评价，如果有多个回归模型，还可以进行比较。

评价的指标包括：

- 决定系数 $ {R}^{2} $

  $ {R}^{2} = \frac{SSR}{SST} = 1-\frac{SSE}{SST} $

  其中：

  SSR: 回归平方和 (sum of squares for regression)

  SST: 总平方和 (sum of squares for total)

  SSE: 残差平方和 (sum of squares for error)

  显然 $ {R}^{2} \leq 1 $。 决定系数越大，表示观测值与拟合值越接近，说明拟合效果越好。

- 剩余标准差 S

  $ S=\sqrt{SSE/(n-2)} $

  S 越小效果越好

- F检验

  $ F=\frac{SSR/1}{SSE/(n-2)} $


# 一元回归

一元线性回归满足如下形式：

$ Y = { \beta }\_{0}+{\beta}\_{1} x + \varepsilon  $

其中:

   $ {\beta}\_{0} , {\beta}\_{1} $ 是参数

   $ \varepsilon $ 是随机误差，且其均值 E(x) =0, 方差 $ var(\varepsilon) =  {\sigma}^{2} $

对于非线性目标函数 $ y = f(x) $ , 回归的一般的思路是：

通过变换:

$
\begin{cases}
& u = u(x) \\\\
& v = v(y)
\end{cases}
$

使得 $ v = a + bu $， 对 v 和 u 进行线性拟合，然后再进行逆变换。

一些简单的非线性模型也可以直接拟合计算，对于这些函数，要熟悉其图形特征：

- 倒幂函数 $ y = a + b \frac{1}{x} $
- 幂函数 $ y = a {x}^{b} $
- 指数函数 $ y = a {e}^{bx} $
- 倒指数函数 $ y = a {e}^{b/x} $
- 对数函数 $ y = a + b ln x $
- S形曲线 $ y = \frac{1}{a + b {e}^{-x}} $

还有一种特殊的一元多项式回归：

$ y = {\beta}\_{0} + {\beta}\_{1} x + ... + {\beta}\_{m} {x}^{m} + \varepsilon $


# 多元回归

多元回归满足 $ Y = f({X}\_{1}, {X}\_{2}, ... , {X}\_{p}) $

其中 :

- Y: 因变量

- $ {X}\_{1}, {X}\_{2}, ... , {X}\_{p} $ :  p 个非随机变量，Y 的解释变量



进行多元回归的一般步骤为：

1. 对问题进行分析，选择因变量与解释变量
2. 作出因变量与各解释变量的散点图，初步设定回归模型参数的个数
3. 输入因变量与自变量的观察数据，计算参数
4. 分析数据异常点情况
5. 进行显著性检验，如果通过，可以用模型进行预测
6. 进一步研究，如残差的正态性检验、残差的异差方检验、残差的自相关性检验等

多元回归一般使用简单的多元线性回归，和多元多项式回归模型。


# 逐步回归


逐步回归的基本思想是有进有出。

具体做法是将变量逐个引入模型，每引入一个解释变量后都要进行F检验，并对已经选入的解释变量逐个进行t检验。
当原来引入的解释变量由于后面解释变量的引入变得不再显著时，则将其删除。
以确保每次引入新的变量之前回归方程中只包含显著性变量。

这是一个反复的过程，直到既没有显著的解释变量选入回归方程，也没有不显著的解释变量从回归方程中剔除为止。
以保证最后所得到的解释变量集是最优的。

依据上述思想，可利用逐步回归筛选并剔除引起多重共线性的变量，其具体步骤如下：

先用被解释变量对每一个所考虑的解释变量做简单回归，
然后以对被解释变量贡献最大的解释变量所对应的回归方程为基础，
再逐步引入其余解释变量。

经过逐步回归，使得最后保留在模型中的解释变量既是重要的，又没有严重多重共线性。


# Logistic回归

一般来说，回归不用在分类问题上，因为回归是连续型模型，而且受噪声影响比较大。如果非要应用进入，可以使用logistic回归。

logistic回归本质上是线性回归（属于广义线性回归，generalized linear model），
但是因变量Y可以是离散值（最典型的时二元的0和1）。

逻辑回归研究某些现象发生的概率，其基本形式为：

$ P(Y=1|{x}\_{1},{x}\_{2},...,{x}\_{k})=
\frac
{exp({\beta}\_{0}+{\beta}\_{1} {x}\_{1} + ... + {\beta}\_{k}{x}\_{k})}
{1+exp({\beta}\_{0}+{\beta}\_{1} {x}\_{1} + ... + {\beta}\_{k}{x}\_{k})}
$

用 `p` 表示Y=1出现的概率，对上述形式进行变换，可以得到：

$ ln \frac{p}{1-p}={\beta}\_{0}+{\beta}\_{1} {x}\_{1} + ... + {\beta}\_{k}{x}\_{k} $

由于定性研究中，p的取值经常只有0、1，上述公式失去意义，所以定义一个单调连续的概率函数 $ \pi $，令：

$ \pi = P(Y=1 | {x}\_{1},{x}\_{2},...{x}\_{k}), 0<\pi<1 $

则Logistic模型变形为：

$ ln \frac{\pi}{1-\pi}={\beta}\_{0}+{\beta}\_{1} {x}\_{1} + ... + {\beta}\_{k}{x}\_{k} ,
0<\pi<1
$

可以用线性回归的方法进行处理。


Logistic回归模型的适用条件：

- 因变量为二分类的分类变量或某事件的发生率，并且是数值型变量。但是需要注意，重复计数现象指标不适用于Logistic回归。
- 残差和因变量都要服从二项分布。二项分布对应的是分类变量，所以不是正态分布，进而不是用最小二乘法，而是最大似然法来解决方程估计和检验问题。
- 自变量和Logistic概率是线性关系
- 各观测对象间相互独立


# 应用实例：多因子选股模型的实现

多因子选股是应用非常广泛的模型。

- 思路

  采用一系列的因子作为选股标准。满足这些因子的股票则买入，不满足的卖出。

  多因子选股的核心，一是因子的选取，二是通过因子进行综合判断。在判断方法上，多采用打分法或者回归法。

  + 打分法：根据各个因子的大小进行打分，然后加权得到股票的总分，再根据总分筛选股票
  + 回归法：用过去的股票收益率对因子进行回归，得到一个关于因子的回归方程，用该回归方程预测股票的收益率，再以此选股

- 过程

  1. 候选因子的选取
  2. 因子有效性检验
  3. 剔除有效但冗余的因子
  4. 建立综合评分模型
  5. 模型的评价和持续改进

  其中，1、2、3、4都可以用回归模型进行处理

- 策略

  略。

